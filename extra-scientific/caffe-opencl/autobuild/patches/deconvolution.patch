diff --git a/src/caffe/libdnn/libdnn_deconv.cpp b/src/caffe/libdnn/libdnn_deconv.cpp
index 576353e4..bc0ed596 100644
--- a/src/caffe/libdnn/libdnn_deconv.cpp
+++ b/src/caffe/libdnn/libdnn_deconv.cpp
@@ -215,6 +215,23 @@ LibDNNDeconv<MItype, MOtype>::LibDNNDeconv(LibDNNDeconvConfig config)
     this->wg_tuner_->add_boolean_param("vector_unroll", true, true);
   }
 
+  bool dp4a = this->dev_ptr_->CheckCapability(DEVICE_CUDA_DP4A_SUPPORT) &&
+      std::is_same<MItype, uint8_t>::value;
+
+  this->fw_tuner_->add_boolean_param("DP4A", dp4a, false);
+  this->bw_tuner_->add_boolean_param("DP4A", dp4a, false);
+  this->wg_tuner_->add_boolean_param("DP4A", dp4a, false);
+
+  this->fw_tuner_->add_boolean_param("no_reg_arrs", false, true);
+  this->bw_tuner_->add_boolean_param("no_reg_arrs", false, false);
+  this->wg_tuner_->add_boolean_param("no_reg_arrs", false, false);
+
+  // Override default parameters with device-specific defaults
+  std::map<string, int64_t> params = this->gemm_like_default_parameters();
+  this->fw_tuner_->load_params(params);
+  this->bw_tuner_->load_params(params);
+  this->wg_tuner_->load_params(params);
+
   this->GenerateKernels();
   this->CompileKernels();
 }
@@ -1659,7 +1676,7 @@ string LibDNNDeconv<MItype, MOtype>::generate_fw_kernels(string name) {
     }
 
     ss << "if (in_range) {" << std::endl;
-    ss << this->program_->template atomic_add<MItype>("(&(Cptr[tiledIndex])",
+    ss << this->program_->template atomic_add<MItype>("&(Cptr[tiledIndex])",
                        "((MItype*)(&(Creg[wm][wn/VWN])))[wn%VWN]") << std::endl;
     ss << "}" << std::endl;
   }
